# model_poisoning

[![Actions Status][actions-badge]][actions-link]
[![PyPI version][pypi-version]][pypi-link]
[![PyPI platforms][pypi-platforms]][pypi-link]

Reproduction study of "Sleeper Agents" (arXiv:2401.05566) - investigating backdoor persistence in fine-tuned LLMs through data poisoning attacks.

## Installation

```bash
python -m pip install model_poisoning
```

From source:
```bash
git clone https://github.com/sam-ghala/model_poisoning
cd model_poisoning
python -m pip install .
```

## Usage


## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to contribute.

## License

Distributed under the terms of the [MIT license](LICENSE).


<!-- prettier-ignore-start -->
[actions-badge]:            https://github.com/sam-ghala/model_poisoning/workflows/CI/badge.svg
[actions-link]:             https://github.com/sam-ghala/model_poisoning/actions
[pypi-link]:                https://pypi.org/project/model_poisoning/
[pypi-platforms]:           https://img.shields.io/pypi/pyversions/model_poisoning
[pypi-version]:             https://img.shields.io/pypi/v/model_poisoning
<!-- prettier-ignore-end -->
